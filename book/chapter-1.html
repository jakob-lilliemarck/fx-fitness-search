<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>In search of predictive ability</title>
        <style>
            :root {
                --primary: #b511d7; /*#4800b0 #ff0080*/
                --text: #222;
                --font-md: 1rem;
                --font-sm: 0.875rem;
                --spacing: 0.25rem;
            }
            html,
            body {
                font-size: var(--font-md);
                font-family:
                    -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
                    "Helvetica Neue", Arial, sans-serif;
                line-height: 1.65;
                color: var(--text);
                display: flex;
                flex: 1 1;
                flex-direction: column;
                justify-content: center;
                margin: 0;
                padding: 0;
            }
            body {
                max-width: 80ch;
                margin: auto;
            }
            article {
                display: flex;
                flex-direction: column;
                padding: calc(16 * var(--spacing)) calc(8 * var(--spacing));
                counter-reset: conclusion;
            }
            article > header {
                margin-bottom: calc(8 * var(--spacing));
                padding-bottom: calc(4 * var(--spacing));
                display: flex;
                flex-direction: column;
            }
            .meta {
                display: flex;
                flex-direction: column;
                align-items: flex-end;
                gap: calc(1 * var(--spacing));
                margin-bottom: calc(2 * var(--spacing));
                font-size: var(--font-sm);
                color: #999;
                text-align: right;
            }
            .meta .author,
            .meta .date {
                display: block;
            }
            section {
                display: flex;
                flex-direction: column;
            }
            /* Add spacing between section elements */
            section > * + * {
                margin: 0;
                margin-top: calc(3 * var(--spacing));
            }
            /* Less spacing before blockquotes */
            section > blockquote {
                margin-top: calc(2 * var(--spacing));
            }
            section + section {
                border-top: 1px solid #eaeaea;
                margin-top: calc(8 * var(--spacing));
                padding-top: calc(6 * var(--spacing));
            }
            h1 {
                font-size: 2.5rem;
                line-height: 1.2;
                margin: 0;
                margin-bottom: calc(4 * var(--spacing));
            }
            h2 {
                font-size: 1.75rem;
                line-height: 1.3;
                margin: 0;
                margin-bottom: calc(2 * var(--spacing));
            }
            a {
                color: var(--primary);
                text-decoration: none;
            }
            a:hover {
                text-decoration: underline;
            }
            table {
                border-collapse: collapse;
                margin: 1rem 0;
            }
            th,
            td {
                border: 1px solid #ddd;
                padding: 0.5rem 0.75rem;
                text-align: left;
            }
            th {
                background-color: #f5f5f5;
                font-weight: bold;
            }
            blockquote {
                background-color: #f9f9f9;
                border-left: 4px solid var(--primary);
                margin: 1rem 0;
                padding: 1rem 1.5rem;
                font-style: italic;
            }
            .conclusion {
                position: relative;
                padding-left: 2ch;
                margin-left: 0;
            }
            .conclusion::before {
                counter-increment: conclusion;
                content: counter(conclusion);
                position: absolute;
                left: 0;
                top: 0;
                font-weight: 700;
                font-size: 1em;
                line-height: 1.65;
                color: var(--primary);
            }
            var,
            code {
                background-color: #f5f5f5;
                color: var(--primary);
                padding: 0.125rem 0.375rem;
                border-radius: var(--spacing);
                font-family: "Courier New", monospace;
                font-size: var(--font-sm);
            }
            pre {
                background-color: #f5f5f5;
                padding: 1rem;
                border-radius: calc(2 * var(--spacing));
                overflow-x: auto;
                margin: calc(3 * var(--spacing)) 0;
                box-sizing: border-box;
                max-width: 100%;
            }
            canvas {
                max-width: 100%;
            }
            pre code {
                background-color: transparent;
                color: inherit;
                padding: 0;
                border-radius: 0;
            }
            /* Mobile optimizations */
            @media (max-width: 768px) {
                :root {
                    --font-md: 0.9rem;
                    --font-sm: 0.8rem;
                }
                article {
                    padding: calc(8 * var(--spacing)) calc(2 * var(--spacing));
                }
                h1 {
                    font-size: 2rem;
                }
                h2 {
                    font-size: 1.5rem;
                }
                pre,
                code {
                    font-size: 0.75rem;
                }
                pre {
                    max-width: calc(100vw - calc(4 * var(--spacing)));
                }
            }
        </style>
        <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>
        <!-- For Prism.js with Night Owl theme -->
        <link
            href="https://cdn.jsdelivr.net/npm/prism-themes@1.9.0/themes/prism-night-owl.min.css"
            rel="stylesheet"
        />
        <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    </head>
    <body>
        
<article>
    <header>
        <div class="meta">
            <span class="author">Jakob Lilliemarck</span>
            <span class="date">December 2025</span>
        </div>
    </header>
    <section>
        <h1>In search of predictive ability</h1>
        <p>
            I've spent the better part of this Autumn thinking about and
            experimenting with machine learning in Rust. Initially I was curious
            if it would be feasible for me to do, and what it would take in
            terms of computational, not to mention cognitive resources - would
            it be within my reach?
        </p>
        <p>
            "Why Rust?", you may ask. Why not Python, or even C? I have been
            asking myself the same question, but truth be told, I find neither
            of which compelling to work with. After all, in most systems (yes,
            even machine learning ones) the majority of the code is not about
            tensors and models, but about data retrieval and processing. If you
            ask me, Rust has it all - excellent support for test driven
            development, memory safety, robust and explicit parallel computing
            and a proper expressive type system. I'd even argue that Rust is a
            simple language because in Rust there are no surprises and there is
            no magic.
        </p>
    </section>

    <section>
        <h2>The Morphological Space of Neural Networks</h2>
        <p>
            I've learned that while doing machine learning, there are a lot of
            decisions to make. How to handle missing data? How to process,
            extract and structure data in a form the models and frameworks will
            accept? Which model, architecture and training parameters to use,
            and for which use-case? The list goes on.
        </p>
        <p>
            From memory, most examples or articles I've seen in the past about
            machine learning (though I must admit I really haven't done my
            homework here) typically involve an enthusiastic author reasoning
            about the validity and meaning of parameters while making one-off
            experiments. That makes me itch. If there's anything equivalent to
            "code smell" for data science, I think that's it—you've got these
            sophisticated models producing measurable predictions, and yet you
            allow your human superstition and poor analytical skills to dictate
            the conditions of your experiments. I can't but ask "why?".
        </p>
        <p>
            Consider a simple model, a feedforward neural network. Even this
            seemingly straightforward architecture exists within a vast space of
            design choices. To illustrate the scale of this space, its
            "morphology" if you will, lets roughly discretize the key dimensions
            that impact model performance:
        </p>
        <table>
            <thead>
                <tr>
                    <th>Variable</th>
                    <th>Choices</th>
                    <th>Count</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Sequence length</td>
                    <td>5, 10, 20, 30, 50</td>
                    <td>5</td>
                </tr>
                <tr>
                    <td>Hidden size</td>
                    <td>32, 64, 128, 256, 512</td>
                    <td>5</td>
                </tr>
                <tr>
                    <td>Activation function</td>
                    <td>ReLU, Tanh, Sigmoid</td>
                    <td>3</td>
                </tr>
                <tr>
                    <td>Epochs</td>
                    <td>10, 25, 50, 100, 200</td>
                    <td>5</td>
                </tr>
                <tr>
                    <td>Batch size</td>
                    <td>16, 32, 64, 128, 256</td>
                    <td>5</td>
                </tr>
                <tr>
                    <td>Learning rate</td>
                    <td>1e-4, 1e-3, 1e-2, 1e-1</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>Optimizer type</td>
                    <td>Adam, SGD, RMSprop</td>
                    <td>3</td>
                </tr>
                <tr>
                    <td>Gradient clipping</td>
                    <td>None, 0.5, 1.0, 2.0</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>Weight decay</td>
                    <td>None, 1e-4, 1e-3, 1e-2</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>Patience</td>
                    <td>None, 5, 10, 20</td>
                    <td>4</td>
                </tr>
                <tr>
                    <td>Model initialization</td>
                    <td>Default, Xavier, He</td>
                    <td>3</td>
                </tr>
            </tbody>
        </table>
        <p>
            That is
            <code>5 × 5 × 3 × 5 × 5 × 4 × 3 × 4 × 4 × 4 × 3 = ~864,000</code>
            possible configurations before even considering the input data or
            its preprocessing!
        </p>
        <p>
            Even for a simple feedforward network, the morphological space is
            massive! Any approach relying on manual experimentation to search
            such is going to be impractical at best - this is a problem that
            calls for a structured quantitative approach.
        </p>
    </section>

    <section>
        <h2>Making sense of the mess</h2>
        <p>
            In a previous job of mine, I worked in an innovation hub at one of
            the larger architectural firms in Sweden. My role at the time was as
            <i>computational designer</i>, an odd title that often provided
            people with more questions than answers. As a title it was not
            ideal, but it was an interesting job. It involved applying
            programming, algorithms and systems thinking to the processes of
            creative exploration and manufacturing of complex three dimensional
            forms. The tool I used allowed for geometric optimization by means
            of a built in genetic algorithm solver. Genetic algorithms (GA) is
            an idea that takes its inspiration from Darwinian evolution theory
            and employs operations such as "mutation" and "crossover" to find
            good candidate solutions. The foundational hypothesis is that two
            fit solutions are likely to have fit offspring. As it turns out GA
            is also a commonly used tool for optimizing machine learning
            systems.
        </p>
        <p>
            A few weeks back, and with all of the above in mind, I wrote a
            simple event driven GA library with Postgres persistence for Rust. I
            will not be going in to the technical details of it now, however I
            welcome you to check it out, should you be interested:
        </p>
        <a href="https://github.com/jakob-lilliemarck/fx-durable-ga"
            >https://github.com/jakob-lilliemarck/fx-durable-ga
        </a>
        <p>The question on my mind was:</p>
        <blockquote>
            Could genetic algorithms be a way to search for "predictive ability"
            over feature selection, preprocessing, model architecture and
            training parameters combined?
        </blockquote>
        <p>
            Searching for a good solution across all of those is after all the
            reality of training just about any model, on any dataset. Surely
            that space is bound to be so large that it's impractical, improbable
            and perhaps even impossible, for any manual process to find a global
            optimum, or even a good local one. As a developer I've come to know
            my human weaknesses well enough that I do not want to pick those
            parameters by hand, but perhaps more importantly: I do not care
            about the parameters, I care about the performance of the system!
        </p>
        <p>
            In search of an answer to my question I set up a project to attempt
            a combined search for predictive ability using the "Beijing
            Multi-Site Air Quality" dataset (Chen, 2017) while making use of my
            new library:
        </p>
        <a href="https://github.com/jakob-lilliemarck/fx-fitness-search"
            >https://github.com/jakob-lilliemarck/fx-fitness-search
        </a>
    </section>

    <section>
        <h2>Genetic encoding and fitness</h2>
        <p>
            So how does one get a genetic algorithm to explore a landscape of
            solutions?
        </p>
        <p>
            In an attempt to shed some light, lets for a moment consider a much
            smaller and much simpler problem. Let's imagine that we're searching
            for a point <var>A</var> within a cube. The closer we get to the
            point, the better is our solution.
        </p>
        <p>
            We represent the cube using the cartesian coordinate system, within
            which it occupies some space along each of the three axes
            <var>X</var>, <var>Y</var> and <var>Z</var>. The geometric bounds of
            the cube could be defined as a maximum and a minimum value along
            each axis. For simplicities sake, let's say the cube occupies the
            space between the origin point <code>[0.0, 0.0, 0.0]</code> and a
            point <code>[1.0, 1.0, 1.0]</code>. The full cube could then be
            represented as the following.
        </p>
        <pre><code class="language-javascript">// X, Y and Z axis
[
  { min: 0.0, max: 1.0 },
  { min: 0.0, max: 1.0 },
  { min: 0.0, max: 1.0 }
]</code></pre>
        <p>
            Knowing that we're searching for a point <i>within</i> the cube we
            can now discard the infinite numbers of points that lie outside it,
            and focus our attention to the much smaller infinite number of
            points that lie within it. In other words, we know the valid ranges
            of values for <var>X</var>, <var>Y</var> and <var>Z</var>, those
            define the <i>morphology</i> of our search space.
        </p>
        <p>
            To compute the <i>fitness</i> of a candidate, we measure its
            distance to point <code>A</code>. Points closer to
            <code>A</code> will have a lower fitness, while points further a
            away will have a higher fitness. Our optimization will strive to
            minimize fitness.
        </p>
        <p>
            Now we mostly have what we need to generate candidate solutions. For
            reasons beyond this example, the framework I've written requires
            genes to be integers, so in order to adapt this example and adhere
            to those requirements we'll also need to define the number of steps,
            the resolution, along each axis. That limits the search space
            further, makes the resolution explicit and the number of
            configuration finite.
        </p>
        <p>
            Every valid point along an axis like
            <code>{ min: 0.0, max: 1.0, steps: 11 }</code>
            could then be described as one of the 11 integer numbers between 0
            and 10. We now possess the means of encoding and decoding a point
            through the morphological bounds of the cube. We call the decoded
            form the <i>phenotype</i>, a term from genetics encompassing the
            observable traits of an organism, and the encoded form the
            <i>genotype</i>, the genetic information of that organism. To give
            an example:
        </p>
        <pre><code class="language-javascript">// Morphology, the space we search solutions within
[
  { min: 0.0, max: 1.0, steps: 11 },
  { min: 0.0, max: 1.0, steps: 11 },
  { min: 0.0, max: 1.0, steps: 11 }
]

// Point candidate solution, phenotype representation
{
  x: 0.2,
  y: 0.1,
  z: 0.9
}

// Candidate solution, encoded to genotype representation
[
  2, // 0.2 * (11 - 1) = 0.2 * 10 = 2,
  1, // 0.1 * (11 - 1) = 0.1 * 10 = 1
  9  // 0.9 * (11 - 1) = 0.9 * 10 = 9
]</code></pre>
        <p>
            This business of encoding and decoding may feel like jumping through
            hoops. However this transformation allows us to represent both
            integer and decimal numbers, booleans and enumerations, which
            together allows for expressing most conceivable search spaces while
            allowing the framework to handle any gene of any search space in a
            uniform manner. Using the morphological definition, the GA framework
            can now <code>generate</code>, <code>breed</code>,
            <code>mutate</code> and <code>evaluate</code> phenotypes. That is
            the foundation of a GA optimization solver.
        </p>
    </section>

    <section>
        <h2>Putting it in context</h2>
        <p>
            Looking at the dataset and considering my question I drew three
            conclusions.
        </p>
        <p class="conclusion">
            I do not know which data points have a strong or weak correlation
            and which would provide valuable information and which would just
            provide noise. Therefore I want the system to freely optimize the
            selection of data points, to include an arbitrary number from those
            available in the dataset.
        </p>
        <p class="conclusion">
            I can not determine which preprocessing methods are suitable to
            extract information from which data points. Therefore I want the
            system to freely optimize the selection and preprocessing methods
            and their parameters for each selected data point.
        </p>
        <p class="conclusion">
            The relationships between the selection of data points,
            preprocessors, training parameters and model architecture may
            contain valuable recognizable patterns. Any attempt at a stepwise
            optimization, for example first optimizing model architecture, and
            then optimizing training parameters, will hide these patterns from
            the system. Therefore I want to optimize them all at once, in a
            <i>combined</i> search for fitness.
        </p>
        <p>
            But representing optional values within our GA poses a new challenge
            as the genotype encoding relies on the position of genes. So how to
            represent those "arbitrary number of" or "up to" expressions?
        </p>
        <p>
            What if we used 2 genes to "wrap" the genes encoding a specific
            attribute? Something like:
        </p>
        <ul>
            <li>
                One gene bounded at 0 and 1 with 2 steps, encoding if the
                wrapped "block" is active or not.
            </li>
            <li>
                One gene bounded between 0 and the number of options (column
                names, preprocessor types, etc.), acting like a "selector".
            </li>
        </ul>
        <pre><code class="language-javascript">[
    // The on/off "block toggle"
    { min: 0.0, max: 1.0, steps: 2 },
    // The "column selector", there are 12 columns of interest
    { min: 0.0, max: 11.0, steps: 12 },
    // .. the wrapped gene(s) follow here
]</code></pre>
        <p>
            This design comes with the constraint that the wrapped genes must be
            of equal length and must share the same number of options per gene.
            While that's far from ideal I decided it was good enough for now.
        </p>
    </section>
    <section>
        <h2>Trying it out</h2>
        <p>
            So, does this complex and computationally expensive approach hold
            any merit? Will it be able to find any promising configurations
            within these immense search spaces?
        </p>
        <p>
            I initiated an optimization using the command below, basing it on
            some past experience that for a given number of evaluations, a
            higher number of generations typically produce better results by
            providing more exploitation.
        </p>
        <pre><code class="language-bash">target/release/client beijing request-optimization \
  --fitness-goal 'MIN(0.0)' \
  --schedule 'GENERATIONAL(100, 12)' \
  --selector 'TOURNAMENT(3, 12)' \
  --mutagen 'MUTAGEN(0.7, 0.4)' \
  --initial-population 50 \
  --prediction-horizon 1 \
  --epochs 20 \
  --patience 3 \
  --validation-start-epoch 5 \
  --batch-size 128</code></pre>
        <p>
            To spell it out, this command requests an optimization that
            minimizes fitness across 100 generations of population size 12. It
            selects parents via tournament selection, sampling 12 genotypes and
            running a tournament of size 3 to select each parent.
            <code>MUTAGEN(0.7, 0.4)</code> sets temperature at 0.7, allowing for
            large changes in the mutation of a single gene (max is at 1.0),
            while a mutation rate of 0.4 gives each gene a 40% chance of
            mutating. The optimization starts with an initial population of 50
            genotypes and trains each candidate model for up to 20 epochs with a
            batch size of 128, stopping early if validation loss fails to
            improve for 3 consecutive epochs (starting from epoch 5). The
            prediction horizon of 1 means the model forecasts one time step
            ahead.
        </p>
        <canvas id="chart-019bcd2b-91dd-7502-85d1-2983cfc65d2b"></canvas>
<script>
    new Chart(document.getElementById('chart-019bcd2b-91dd-7502-85d1-2983cfc65d2b'), {"type":"line","data":{"labels":["Gen 1","Gen 2","Gen 3","Gen 4","Gen 5","Gen 6","Gen 7","Gen 8","Gen 9","Gen 10","Gen 11","Gen 12","Gen 13","Gen 14","Gen 15","Gen 16","Gen 17","Gen 18","Gen 19","Gen 20","Gen 21","Gen 22","Gen 23","Gen 24","Gen 25","Gen 26","Gen 27","Gen 28","Gen 29","Gen 30","Gen 31","Gen 32","Gen 33","Gen 34","Gen 35","Gen 36","Gen 37","Gen 38","Gen 39","Gen 40","Gen 41","Gen 42","Gen 43","Gen 44","Gen 45","Gen 46","Gen 47","Gen 48","Gen 49","Gen 50","Gen 51","Gen 52","Gen 53","Gen 54","Gen 55","Gen 56","Gen 57","Gen 58","Gen 59","Gen 60","Gen 61","Gen 62","Gen 63","Gen 64","Gen 65","Gen 66"],"datasets":[{"label":"Average fitness","data":[20.18,30.51,23.5,24.61,16.96,56.75,18.96,14.2,45.58,18.63,33.85,39.67,12.79,24.11,11.71,27.01,12.6,23.62,12.47,40.84,25.28,11.29,21.81,15.99,10.63,59.16,45.02,42.99,15.92,37.1,48.19,27.58,37.36,25.83,10.37,27.1,26.56,13.24,47.14,12.38,12.61,24.66,21.43,28.1,26.77,26.4,50.82,22.71,27.5,30.8,23.83,33.96,37.52,20.67,14.63,9.88,11.82,29.45,47.54,20.65,70.05,24.03,22.86,57.19,13.26,12.3],"borderColor":"rgb(75, 192, 192)","tension":0.1,"pointRadius":0.0,"borderWidth":1.5},{"label":"Trend: Average fitness","data":[25.5265,25.576002,25.625504,25.675005,25.724506,25.77401,25.823511,25.873013,25.922514,25.972015,26.021517,26.071018,26.12052,26.170021,26.219522,26.269026,26.318527,26.368029,26.41753,26.467031,26.516533,26.566034,26.615536,26.665037,26.714539,26.764042,26.813543,26.863045,26.912546,26.962048,27.011549,27.06105,27.110552,27.160053,27.209557,27.259058,27.30856,27.35806,27.407562,27.457064,27.506565,27.556067,27.605568,27.655071,27.70457,27.754074,27.803576,27.853077,27.902578,27.95208,28.001581,28.051083,28.100584,28.150085,28.199589,28.24909,28.298592,28.348093,28.397594,28.447096,28.496597,28.546099,28.5956,28.645103,28.694605,28.744106],"borderColor":"rgb(255, 99, 132)","tension":0.0,"pointRadius":0.0,"borderWidth":1.0}]},"options":{"animation":false,"aspectRatio":1.7}});
</script>
        <p>
            This graph shows the resulting <i>average fitness</i> per generation
            after running the above command for about 65 generations, after
            which I saw no point in keeping it running. While it did indeed find
            some decent configurations there were no signs that the system could
            effectively exploit the solutions it had found to produce better
            ones. In fact, it did not really seem any better than a random
            search!
        </p>
        <p>
            It was a disappointing result but I wasn't expecting success to come
            cheaply. Perhaps my optimization settings were too geared towards
            <i>exploration</i> and too little towards <i>exploitation</i>? The
            relationship between the two is typically a fickle thing with GAs,
            and while I did get the feeling my work was just moving the buttons
            and levers one step further from the actual problem, I tried to
            ignore it for the time being. I needed more tests, more results!
        </p>
    </section>
    <section>
        <h2>Trying again</h2>
        <p>
            I re-wrote the project into a client-server architecture, rented a
            cheap VM to run a database and configured SSH access between my
            devices and the server. My devices could now cooperatively work on
            the same optimization request to resolve it faster and at larger
            scale than before. With that setup I ran the following command.
        </p>
        <pre><code class="language-bash">target/release/client beijing request-optimization \
  --fitness-goal 'MIN(0.0)' \
  --schedule 'GENERATIONAL(100, 48)' \
  --selector 'TOURNAMENT(5, 400)' \
  --mutagen 'MUTAGEN(0.3, 0.15)' \
  --initial-population 200 \
  --prediction-horizon 1 \
  --epochs 30 \
  --patience 3 \
  --validation-start-epoch 5 \
  --batch-size 128</code></pre>
        <p>
            This request uses larger populations, larger tournament and sample
            sizes, lower temperature and mutation rate as well as a much larger
            initial population to put significant more emphasis on exploitation.
        </p>
        <canvas id="chart-019bcd2b-91de-7e41-a330-0e45826bdf5a"></canvas>
<script>
    new Chart(document.getElementById('chart-019bcd2b-91de-7e41-a330-0e45826bdf5a'), {"type":"line","data":{"labels":["Gen 1","Gen 2","Gen 3","Gen 4","Gen 5","Gen 6","Gen 7","Gen 8","Gen 9","Gen 10","Gen 11","Gen 12","Gen 13","Gen 14","Gen 15","Gen 16","Gen 17","Gen 18","Gen 19","Gen 20","Gen 21","Gen 22","Gen 23","Gen 24","Gen 25","Gen 26","Gen 27","Gen 28","Gen 29","Gen 30","Gen 31","Gen 32","Gen 33","Gen 34","Gen 35","Gen 36","Gen 37","Gen 38","Gen 39","Gen 40","Gen 41","Gen 42","Gen 43","Gen 44","Gen 45","Gen 46","Gen 47","Gen 48","Gen 49","Gen 50","Gen 51","Gen 52","Gen 53","Gen 54","Gen 55","Gen 56","Gen 57","Gen 58","Gen 59","Gen 60","Gen 61","Gen 62","Gen 63","Gen 64","Gen 65","Gen 66","Gen 67","Gen 68","Gen 69","Gen 70","Gen 71","Gen 72","Gen 73","Gen 74","Gen 75","Gen 76","Gen 77","Gen 78","Gen 79","Gen 80","Gen 81","Gen 82","Gen 83","Gen 84","Gen 85","Gen 86","Gen 87","Gen 88","Gen 89","Gen 90","Gen 91","Gen 92","Gen 93","Gen 94","Gen 95","Gen 96","Gen 97"],"datasets":[{"label":"Average fitness","data":[30.48,17.54,13.58,14.51,10.99,15.29,9.43,13.49,16.29,9.1,10.31,14.94,4.9,18.69,13.46,4.16,15.22,11.45,10.24,4.43,9.98,5.96,13.82,9.2,7.18,11.89,10.35,11.03,7.33,3.68,10.45,7.01,13.08,11.26,7.94,12.2,11.22,9.18,11.51,6.13,7.97,8.62,4.16,11.22,3.61,5.02,8.44,4.14,7.11,2.41,7.3,3.63,6.44,9.74,6.67,6.34,11.32,9.69,9.56,9.29,10.76,4.05,6.7,6.37,9.36,8.0,8.9,4.05,7.54,9.08,17.78,7.25,11.4,5.07,11.8,3.9,7.78,7.71,7.43,7.36,4.16,8.41,6.8,3.25,6.12,6.7,8.67,10.44,11.31,6.5,4.85,5.87,8.35,7.16,3.36,12.16,7.21],"borderColor":"rgb(75, 192, 192)","tension":0.1,"pointRadius":0.0,"borderWidth":1.5},{"label":"Trend: Average fitness","data":[12.253994,12.186673,12.119351,12.052031,11.98471,11.917388,11.850067,11.782745,11.715425,11.648104,11.580782,11.513461,11.44614,11.3788185,11.311498,11.244177,11.176855,11.109534,11.0422125,10.974892,10.907571,10.840249,10.772928,10.705606,10.638286,10.570965,10.503643,10.436322,10.369001,10.30168,10.234359,10.167038,10.099716,10.032395,9.965075,9.897753,9.830432,9.763111,9.695789,9.6284685,9.561147,9.493826,9.426504,9.359183,9.2918625,9.224541,9.15722,9.089899,9.022577,8.955256,8.887936,8.820614,8.753293,8.685972,8.61865,8.55133,8.484009,8.416687,8.349366,8.282044,8.214724,8.147402,8.080081,8.01276,7.945439,7.8781176,7.8107967,7.7434754,7.676154,7.608833,7.541512,7.4741907,7.4068694,7.339548,7.2722273,7.204906,7.1375847,7.0702634,7.0029426,6.9356213,6.8683,6.800979,6.733658,6.6663365,6.599015,6.5316944,6.464373,6.397052,6.3297305,6.2624097,6.1950884,6.127767,6.060446,5.993125,5.9258037,5.8584824,5.7911615],"borderColor":"rgb(255, 99, 132)","tension":0.0,"pointRadius":0.0,"borderWidth":1.0}]},"options":{"animation":false,"aspectRatio":1.7}});
</script>
        <p>
            Look at that! Average fitness is actually decreasing, at least for
            the 50 first generations or so. This time around the GA undoubtedly
            found patterns it could exploit.
        </p>
        <p>
            But hold on—what does it even mean for average fitness to decrease?
            Who cares about <i>average fitness</i>? At the end of the day,
            average fitness is not what is going to get us a better prediction!
            It does give us some affirmation that the GA system works, and that
            there is some merit to the idea that two fit genotypes are more
            likely to have fit offspring. However, in relation to the problem at
            hand—predicting temperature one time step ahead with the lowest
            possible loss—we're really <i>only</i> interested in the best
            performing configurations: the minimum fitness of each generation.
        </p>
        <canvas id="chart-019bcd2b-91df-7ef2-a55a-f500c3684b0b"></canvas>
<script>
    new Chart(document.getElementById('chart-019bcd2b-91df-7ef2-a55a-f500c3684b0b'), {"type":"line","data":{"labels":["Gen 1","Gen 2","Gen 3","Gen 4","Gen 5","Gen 6","Gen 7","Gen 8","Gen 9","Gen 10","Gen 11","Gen 12","Gen 13","Gen 14","Gen 15","Gen 16","Gen 17","Gen 18","Gen 19","Gen 20","Gen 21","Gen 22","Gen 23","Gen 24","Gen 25","Gen 26","Gen 27","Gen 28","Gen 29","Gen 30","Gen 31","Gen 32","Gen 33","Gen 34","Gen 35","Gen 36","Gen 37","Gen 38","Gen 39","Gen 40","Gen 41","Gen 42","Gen 43","Gen 44","Gen 45","Gen 46","Gen 47","Gen 48","Gen 49","Gen 50","Gen 51","Gen 52","Gen 53","Gen 54","Gen 55","Gen 56","Gen 57","Gen 58","Gen 59","Gen 60","Gen 61","Gen 62","Gen 63","Gen 64","Gen 65","Gen 66","Gen 67","Gen 68","Gen 69","Gen 70","Gen 71","Gen 72","Gen 73","Gen 74","Gen 75","Gen 76","Gen 77","Gen 78","Gen 79","Gen 80","Gen 81","Gen 82","Gen 83","Gen 84","Gen 85","Gen 86","Gen 87","Gen 88","Gen 89","Gen 90","Gen 91","Gen 92","Gen 93","Gen 94","Gen 95","Gen 96","Gen 97"],"datasets":[{"label":"Minimum fitness","data":[0.73,0.69,0.69,0.7,0.69,0.7,0.67,0.66,0.66,0.68,0.68,0.68,0.72,0.68,0.66,0.69,0.7,0.69,0.7,0.65,0.69,0.68,0.69,0.67,0.67,0.69,0.68,0.69,0.67,0.65,0.69,0.67,0.67,0.69,0.7,0.67,0.68,0.68,0.66,0.66,0.69,0.66,0.69,0.66,0.68,0.68,0.69,0.68,0.67,0.67,0.66,0.67,0.68,0.69,0.67,0.69,0.67,0.68,0.69,0.66,0.67,0.67,0.68,0.67,0.68,0.66,0.66,0.66,0.68,0.67,0.67,0.65,0.67,0.68,0.66,0.69,0.66,0.66,0.68,0.67,0.69,0.67,0.68,0.69,0.68,0.66,0.68,0.68,0.7,0.69,0.66,0.69,0.69,0.68,0.69,0.7,0.67],"borderColor":"rgb(75, 192, 192)","tension":0.1,"pointRadius":0.0,"borderWidth":1.5},{"label":"Trend: Minimum fitness","data":[0.68308705,0.6829862,0.6828854,0.68278456,0.6826837,0.68258286,0.68248206,0.6823812,0.68228036,0.6821796,0.6820787,0.68197787,0.681877,0.6817762,0.6816754,0.6815745,0.68147373,0.6813729,0.68127203,0.6811712,0.6810704,0.68096954,0.6808687,0.6807679,0.68066704,0.6805662,0.6804654,0.68036455,0.6802637,0.68016285,0.68006206,0.6799612,0.67986035,0.67975956,0.6796587,0.67955786,0.679457,0.6793562,0.67925537,0.6791545,0.6790537,0.6789529,0.678852,0.6787512,0.6786504,0.6785495,0.6784487,0.6783479,0.67824703,0.6781462,0.67804533,0.67794454,0.6778437,0.67774284,0.67764205,0.6775412,0.67744035,0.6773395,0.6772387,0.67713785,0.677037,0.6769362,0.67683536,0.6767345,0.67663366,0.67653286,0.676432,0.67633116,0.6762304,0.6761295,0.67602867,0.6759279,0.675827,0.6757262,0.6756253,0.67552453,0.6754237,0.67532283,0.67522204,0.6751212,0.67502034,0.6749195,0.6748187,0.67471784,0.674617,0.6745162,0.67441535,0.6743145,0.67421365,0.67411286,0.674012,0.67391115,0.67381036,0.6737095,0.67360866,0.6735078,0.673407],"borderColor":"rgb(255, 99, 132)","tension":0.0,"pointRadius":0.0,"borderWidth":1.0}]},"options":{"animation":false,"aspectRatio":1.7}});
</script>
        <p>
            That's interesting—while average fitness steadily decreases, the
            minimum fitness doesn't really change much during the optimization.
            The slight drop in the chart trend line is so small that it's
            essentially negligible. What are we to make of that? Here are two
            thoughts.
        </p>
        <p class="conclusion">
            The system is not actively retaining a set of elite candidates
            throughout generations, instead sampling randomly from all evaluated
            genotypes across the entire optimization history. Without elite
            retention, the system may be losing and re-discovering similar
            solutions time and time again but failing to progress from them.
        </p>
        <p class="conclusion">
            The single-point crossover operation is agnostic to the logical
            structure of gene blocks, meaning it can split blocks mid-way and
            create configurations where toggles, selectors, and wrapped genes
            become misaligned. This could be introducing significant noise into
            the fitness landscape, corrupting the evolutionary signal and
            preventing the algorithm from reliably building upon promising
            solutions.
        </p>
    </section>
    <section>
        <h2>Looking Forward</h2>
        <p>
            So, did it work? Honestly, I'm not sure. The fact that average
            fitness decreased suggests the system found something to latch
            onto—patterns it could exploit. But the core question remains: can
            this approach consistently improve minimum fitness across
            generations? That's what actually matters, and right now I simply
            don't have enough evidence to say.
        </p>
        <p>
            That said, this wasn't a complete dead end. The analysis surfaced
            two concrete improvements worth trying. First, implementing
            <i>elite retention</i>—guaranteeing the best solutions always make
            it into the breeding pool rather than getting randomly excluded.
            Second, considering <i>genetic programming</i> instead of genetic
            algorithms. GP operates on tree structures rather than flat arrays,
            which would naturally handle the "if this feature is enabled, then
            apply this preprocessing" logic without crossover tearing it apart.
        </p>
        <p>
            If nothing else, I learned to look at minimum fitness rather than
            averages and got a better feel for the exploration-exploitation
            tradeoff. Whether that translates into actually solving the
            problem—well, that's a question for another experiment.
        </p>
    </section>
</article>

    </body>
</html>